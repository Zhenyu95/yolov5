{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "distributed-norfolk",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "scikit-learn version 0.24.1 is not supported. Minimum required version: 0.17. Maximum required version: 0.19.2. Disabling scikit-learn conversion API.\n",
      "TensorFlow version 2.5.0 detected. Last version known to be fully compatible is 2.3.1 .\n",
      "Keras version 2.5.0 detected. Last version known to be fully compatible of Keras is 2.2.4 .\n",
      "Adding op 'pow' of type pow\n",
      "Adding op 'pow_y_0' of type const\n",
      "Adding op 'mul_1' of type mul\n",
      "Adding op 'mul_1_x_0' of type const\n",
      "Adding op 'add' of type add\n",
      "Adding op 'mul_2' of type mul\n",
      "Adding op 'mul_2_x_0' of type const\n",
      "Adding op 'tanh' of type tanh\n",
      "Adding op 'add_1' of type add\n",
      "Adding op 'add_1_x_0' of type const\n",
      "Adding op 'mul' of type mul\n",
      "Adding op 'mul_x_0' of type const\n",
      "Adding op 'mul_3' of type mul\n",
      "Adding op 'pow' of type pow\n",
      "Adding op 'pow_y_1' of type const\n",
      "Adding op 'mul_1' of type mul\n",
      "Adding op 'mul_1_x_1' of type const\n",
      "Adding op 'add' of type add\n",
      "Adding op 'mul_2' of type mul\n",
      "Adding op 'mul_2_x_1' of type const\n",
      "Adding op 'tanh' of type tanh\n",
      "Adding op 'add_1' of type add\n",
      "Adding op 'add_1_x_1' of type const\n",
      "Adding op 'mul' of type mul\n",
      "Adding op 'mul_x_1' of type const\n",
      "Adding op 'mul_3' of type mul\n",
      "Adding op 'main_reduce' of type reduce_mean\n",
      "Adding op 'main_reduce_axes_0' of type const\n",
      "Adding op 'main_reduce_keep_dims_0' of type const\n",
      "Adding op 'sub' of type sub\n",
      "Adding op 'square' of type square\n",
      "Adding op 'reduce_mean_2' of type reduce_mean\n",
      "Adding op 'reduce_mean_2_axes_0' of type const\n",
      "Adding op 'reduce_mean_2_keep_dims_0' of type const\n",
      "Adding op 'add_epsilon' of type add\n",
      "Adding op 'add_epsilon_y_0' of type const\n",
      "Adding op 'rsqrt' of type rsqrt\n",
      "Adding op 'rsqrt_epsilon_0' of type const\n",
      "Adding op 'mul_gamma' of type mul\n",
      "Adding op 'mul_gamma_y_0' of type const\n",
      "Adding op 'mul_2' of type mul\n",
      "Adding op 'mul_3' of type mul\n",
      "Adding op 'sub_beta' of type sub\n",
      "Adding op 'sub_beta_x_0' of type const\n",
      "Adding op 'add_2' of type add\n",
      "Adding op 'main_reduce' of type reduce_mean\n",
      "Adding op 'main_reduce_axes_1' of type const\n",
      "Adding op 'main_reduce_keep_dims_1' of type const\n",
      "Adding op 'sub0' of type sub\n",
      "Adding op 'sub1' of type sub\n",
      "Adding op 'square' of type square\n",
      "Adding op 'mean1' of type reduce_mean\n",
      "Adding op 'mean1_axes_0' of type const\n",
      "Adding op 'mean1_keep_dims_0' of type const\n",
      "Adding op 'add_epsilon' of type add\n",
      "Adding op 'add_epsilon_y_1' of type const\n",
      "Adding op 'pow' of type pow\n",
      "Adding op 'pow_y_2' of type const\n",
      "Adding op 'real_div' of type real_div\n",
      "Adding op 'mul_gamma' of type mul\n",
      "Adding op 'mul_gamma_x_0' of type const\n",
      "Adding op 'add_beta' of type add\n",
      "Adding op 'add_beta_x_0' of type const\n",
      "Adding op 'main_reduce' of type reduce_mean\n",
      "Adding op 'main_reduce_axes_2' of type const\n",
      "Adding op 'main_reduce_keep_dims_2' of type const\n",
      "Adding op 'sub' of type sub\n",
      "Adding op 'square' of type square\n",
      "Adding op 'mean1' of type reduce_mean\n",
      "Adding op 'mean1_axes_1' of type const\n",
      "Adding op 'mean1_keep_dims_1' of type const\n",
      "Adding op 'add_epsilon' of type add\n",
      "Adding op 'add_epsilon_y_2' of type const\n",
      "Adding op 'rsqrt' of type rsqrt\n",
      "Adding op 'rsqrt_epsilon_1' of type const\n",
      "Adding op 'mul1' of type mul\n",
      "Adding op 'mul2' of type mul\n",
      "Adding op 'mul_sub' of type mul\n",
      "Adding op 'mul_sub_y_0' of type const\n",
      "Adding op 'add' of type add\n",
      "Adding op 'mul_square1' of type mul\n",
      "Adding op 'main_reduce' of type reduce_sum\n",
      "Adding op 'main_reduce_axes_3' of type const\n",
      "Adding op 'main_reduce_keep_dims_3' of type const\n",
      "Adding op 'mul_mean' of type mul\n",
      "Adding op 'mul_mean_y_0' of type const\n",
      "Adding op 'mul_square' of type mul\n",
      "Adding op 'sum1' of type reduce_sum\n",
      "Adding op 'sum1_axes_0' of type const\n",
      "Adding op 'sum1_keep_dims_0' of type const\n",
      "Adding op 'mul_mean1' of type mul\n",
      "Adding op 'mul_mean1_y_0' of type const\n",
      "Adding op 'sub_variance' of type sub\n",
      "Adding op 'add_epsilon' of type add\n",
      "Adding op 'add_epsilon_y_3' of type const\n",
      "Adding op 'rsqrt' of type rsqrt\n",
      "Adding op 'rsqrt_epsilon_2' of type const\n",
      "Adding op 'mul_gamma' of type mul\n",
      "Adding op 'mul_gamma_y_1' of type const\n",
      "Adding op 'mul1' of type mul\n",
      "Adding op 'mul2' of type mul\n",
      "Adding op 'sub_beta' of type sub\n",
      "Adding op 'sub_beta_x_1' of type const\n",
      "Adding op 'add' of type add\n",
      "Adding op 'linear' of type linear\n",
      "Adding op 'linear_weight_0' of type const\n",
      "Adding op 'linear_bias_0' of type const\n",
      "Adding op 'add_or_sub' of type add\n",
      "Adding op 'add_or_sub_y_0' of type const\n",
      "Adding op 'linear' of type linear\n",
      "Adding op 'linear_weight_1' of type const\n",
      "Adding op 'linear_bias_1' of type const\n",
      "Adding op 'add_or_sub' of type sub\n",
      "Adding op 'add_or_sub_y_1' of type const\n",
      "Adding op 'conv' of type conv\n",
      "Adding op 'conv_weight_0' of type const\n",
      "Adding op 'conv_pad_type_0' of type const\n",
      "Adding op 'conv_strides_0' of type const\n",
      "Adding op 'conv_pad_0' of type const\n",
      "Adding op 'conv_dilations_0' of type const\n",
      "Adding op 'conv_groups_0' of type const\n",
      "Adding op 'batchnorm' of type batch_norm\n",
      "Adding op 'batchnorm_mean_0' of type const\n",
      "Adding op 'batchnorm_variance_0' of type const\n",
      "Adding op 'batchnorm_epsilon_0' of type const\n",
      "Adding op 'conv' of type conv_transpose\n",
      "Adding op 'conv_weight_1' of type const\n",
      "Adding op 'conv_pad_type_1' of type const\n",
      "Adding op 'conv_pad_1' of type const\n",
      "Adding op 'conv_strides_1' of type const\n",
      "Adding op 'conv_dilations_1' of type const\n",
      "Adding op 'conv_groups_1' of type const\n",
      "Adding op 'batchnorm' of type batch_norm\n",
      "Adding op 'batchnorm_mean_1' of type const\n",
      "Adding op 'batchnorm_variance_1' of type const\n",
      "Adding op 'batchnorm_epsilon_1' of type const\n",
      "Adding op 'conv' of type conv\n",
      "Adding op 'conv_weight_2' of type const\n",
      "Adding op 'conv_pad_type_2' of type const\n",
      "Adding op 'conv_strides_2' of type const\n",
      "Adding op 'conv_pad_2' of type const\n",
      "Adding op 'conv_dilations_2' of type const\n",
      "Adding op 'conv_groups_2' of type const\n",
      "Adding op 'scale' of type mul\n",
      "Adding op 'scale_y_0' of type const\n",
      "Adding op 'conv' of type conv_transpose\n",
      "Adding op 'conv_weight_3' of type const\n",
      "Adding op 'conv_pad_type_3' of type const\n",
      "Adding op 'conv_pad_3' of type const\n",
      "Adding op 'conv_strides_3' of type const\n",
      "Adding op 'conv_dilations_3' of type const\n",
      "Adding op 'conv_groups_3' of type const\n",
      "Adding op 'scale' of type mul\n",
      "Adding op 'scale_y_1' of type const\n",
      "Adding op 'conv' of type conv\n",
      "Adding op 'conv_weight_4' of type const\n",
      "Adding op 'conv_pad_type_4' of type const\n",
      "Adding op 'conv_strides_4' of type const\n",
      "Adding op 'conv_pad_4' of type const\n",
      "Adding op 'conv_dilations_4' of type const\n",
      "Adding op 'conv_groups_4' of type const\n",
      "Adding op 'scale' of type real_div\n",
      "Adding op 'scale_y_2' of type const\n",
      "Adding op 'cast_0' of type cast\n",
      "Adding op 'cast_0_dtype_0' of type const\n",
      "Adding op 'conv' of type conv_transpose\n",
      "Adding op 'conv_weight_5' of type const\n",
      "Adding op 'conv_pad_type_5' of type const\n",
      "Adding op 'conv_pad_5' of type const\n",
      "Adding op 'conv_strides_5' of type const\n",
      "Adding op 'conv_dilations_5' of type const\n",
      "Adding op 'conv_groups_5' of type const\n",
      "Adding op 'scale' of type real_div\n",
      "Adding op 'scale_y_3' of type const\n",
      "Adding op 'cast_1' of type cast\n",
      "Adding op 'cast_1_dtype_0' of type const\n"
     ]
    }
   ],
   "source": [
    "from models.yolo import Detect\n",
    "from utils.general import scale_coords, non_max_suppression, xyxy2xywh\n",
    "import coremltools\n",
    "from PIL import Image\n",
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "import cv2\n",
    "import os\n",
    "import shutil\n",
    "import PIL.Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "applicable-liability",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONSTANTS\n",
    "# COREML_MODEL = \"/Users/zhenyu/Documents/Scripts/IphoneAOI/yolov5/best_1106.mlmodel\"\n",
    "COREML_MODEL = \"/Users/zhenyu/Desktop/exp6/weights/best.mlmodel\"\n",
    "IMAGE_FOLDER = \"/Users/zhenyu/Desktop/val/\"\n",
    "OUT_FOLDER = \"/Users/zhenyu/Desktop/test/\"\n",
    "SAVE_IMG = True\n",
    "VIEW_IMG = False\n",
    "SAVE_TXT = True\n",
    "CAT_NAMES = ['Screw', 'unknown']\n",
    "COLORS = [[random.randint(0, 255) for _ in range(3)] for _ in range(len(CAT_NAMES))]\n",
    "PATH = \"./\"\n",
    "ANCHORS = ([116,90, 156,198, 373,326], [30,61, 62,45, 59,119], [10,13, 16,30, 33,23]) # from <model>.yml\n",
    "IMG_SIZE = (2304, 3072)\n",
    "# IMG_SIZE = (2560, 2560)\n",
    "\n",
    "# GLOBAL VARIABLES\n",
    "nc = len(CAT_NAMES)\n",
    "nl = len(ANCHORS)\n",
    "na = len(ANCHORS[0]) // 2\n",
    "no = nc + 5  # number of outputs per anchor\n",
    "grid = [torch.zeros(1)] * nl  # init grid\n",
    "a = torch.tensor(ANCHORS).float().view(nl, -1, 2)\n",
    "anchor_grid = a.clone().view(nl, 1, -1, 1, 1, 2)\n",
    "# stride for 2304,3072\n",
    "stride = [32, 8, 16]\n",
    "# stride for 2560,2560\n",
    "# stride = [32, 64, 16]\n",
    "conf_thres = .3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "adult-productivity",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(path, resize_to=None):\n",
    "    # resize_to: (Width, Height)\n",
    "    img = PIL.Image.open(path)\n",
    "    if resize_to is not None:\n",
    "        img = img.resize(resize_to, PIL.Image.ANTIALIAS)\n",
    "    img_np = np.array(img).astype(np.float32)\n",
    "    return img_np, img\n",
    "\n",
    "def make_grid(nx=20, ny=20):\n",
    "    yv, xv = torch.meshgrid([torch.arange(ny), torch.arange(nx)])\n",
    "    return torch.stack((xv, yv), 2).view((1, 1, ny, nx, 2)).float()\n",
    "\n",
    "def resize_image(source_image):\n",
    "    background = PIL.Image.new('RGB', IMG_SIZE, \"black\")\n",
    "    source = source_image.copy()\n",
    "    source.thumbnail(IMG_SIZE)\n",
    "    (w, h) = source.size\n",
    "    background.paste(source, (int((IMG_SIZE[0] - w) / 2), int((IMG_SIZE[1] - h) / 2 )))\n",
    "    return background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "detected-plaintiff",
   "metadata": {},
   "outputs": [],
   "source": [
    "source = PIL.Image.open(os.path.join(IMAGE_FOLDER, '2.jpg'))\n",
    "resized = resize_image(source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "accessory-yugoslavia",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3024, 4032)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "geographic-closer",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(file_name):   \n",
    "    source = PIL.Image.open(os.path.join(IMAGE_FOLDER, file_name))\n",
    "    resized = resize_image(source)\n",
    "    # image0shape = np.array(image).astype(np.float32).shape\n",
    "    \n",
    "    # img_np = np.array(img).astype(np.float32)\n",
    "#TODO: BUG HERE!!!!!!!!!!!!!!!\n",
    "    # img = torch.zeros((1,3,IMG_SIZE[0],IMG_SIZE[1]))\n",
    "    # img[0, :, :, :] = torch.Tensor(np.array(resized)).permute(2, 0, 1)\n",
    "    # im0 = np.array(source)\n",
    "\n",
    "    predictions = model.predict({'image': resized})\n",
    "\n",
    "    z = []  # inference output\n",
    "    x = []\n",
    "    for pred in predictions:\n",
    "        x.append(torch.Tensor(predictions[pred]))\n",
    "    x.reverse()\n",
    "\n",
    "    for i in range(nl):\n",
    "        bs, _, ny, nx, _ = x[i].shape\n",
    "\n",
    "        if grid[i].shape[2:4] != x[i].shape[2:4]:\n",
    "            grid[i] = make_grid(nx, ny)\n",
    "\n",
    "        y = x[i].sigmoid()\n",
    "        y[..., 0:2] = (y[..., 0:2] * 2. - 0.5 + grid[i]) * stride[i]  # xy\n",
    "        y[..., 2:4] = (y[..., 2:4] * 2) ** 2 * anchor_grid[i]  # wh\n",
    "        z.append(y.view(bs, -1, no))\n",
    "    \n",
    "    pred = (torch.cat(z, 1), x)[0]\n",
    "\n",
    "    pred = non_max_suppression(pred, conf_thres, .3, classes=None, agnostic=False)\n",
    "    pred_reserve = pred.copy()\n",
    "\n",
    "    # Process detections\n",
    "    for i, det in enumerate(pred):  # detections per image\n",
    "        p, s = \"./\", \"\"\n",
    "\n",
    "        if det is not None and len(det):\n",
    "            # Rescale boxes from img_size to im0 size\n",
    "#             det[:, :4] = scale_coords(resized.size, det[:, :4], source.size).round()\n",
    "            det = det[((det[:, 0]-det[:, 2])*(det[:, 1]-det[:, 3])) > 80]\n",
    "\n",
    "            # Print results\n",
    "            for c in det[:, -1].unique():\n",
    "                n = (det[:, -1] == c).sum()  # detections per class\n",
    "                s += '%g %ss, ' % (n, CAT_NAMES[int(c)])  # add to string\n",
    "\n",
    "            # Write results\n",
    "            for *xyxy, conf, cls in det:\n",
    "                if SAVE_TXT:  # Write to file\n",
    "#                     xywh = (xyxy2xywh(torch.tensor(xyxy).view(1, 4)/np.array([3024, 4032, 3024, 4032]))).view(-1).tolist()\n",
    "                    xywh = (xyxy2xywh(torch.tensor(xyxy).view(1, 4)/np.array([2304, 3072, 2304, 3072]))).view(-1).tolist()\n",
    "                    with open(os.path.join(OUT_FOLDER, 'result_1.txt'), 'a') as f:\n",
    "                        f.write(('%g ' * 5 + '\\n') % (cls, *xywh))  # label format\n",
    "    return source, resized, xywh, pred, pred_reserve, z, predictions, x\n",
    "#         source.save(os.path.join(OUT_FOLDER, 'result_1.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "married-reminder",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = coremltools.models.model.MLModel(COREML_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "vulnerable-venezuela",
   "metadata": {},
   "outputs": [],
   "source": [
    "source, resized, xywh, pred, pred_reserve, z, predictions, x = eval('1_4032.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "modern-cloud",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 40, 40, 7])"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "documented-headset",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "var_1808:(1, 3, 48, 36, 7)\n",
      "var_1778:(1, 3, 192, 144, 7)\n",
      "var_1763:(1, 3, 384, 288, 7)\n",
      "var_1793:(1, 3, 96, 72, 7)\n"
     ]
    }
   ],
   "source": [
    "for each in predictions.keys():\n",
    "    print('{}:{}'.format(each, predictions[each].shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "architectural-arthritis",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pred[0][((pred[0][:, 0]-pred[0][:, 2])*(pred[0][:, 1]-pred[0][:, 3])) > 80]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "dense-meeting",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.45282e+03, 1.45009e+03, 1.50923e+03, 1.53559e+03, 8.58536e-01, 0.00000e+00],\n",
       "        [8.11149e+02, 2.51468e+02, 8.65843e+02, 3.34357e+02, 8.56946e-01, 0.00000e+00],\n",
       "        [1.32890e+03, 6.14181e+02, 1.38540e+03, 6.95824e+02, 8.49743e-01, 0.00000e+00],\n",
       "        [1.32848e+03, 1.39324e+03, 1.36927e+03, 1.45567e+03, 8.44309e-01, 0.00000e+00],\n",
       "        [8.95427e+02, 1.55035e+02, 9.40290e+02, 2.22714e+02, 8.43017e-01, 0.00000e+00],\n",
       "        [8.04034e+02, 4.29946e+02, 8.54911e+02, 5.09081e+02, 8.40511e-01, 0.00000e+00],\n",
       "        [1.42461e+03, 2.20768e+03, 1.47910e+03, 2.29305e+03, 8.38835e-01, 0.00000e+00],\n",
       "        [1.33620e+03, 1.30665e+03, 1.38581e+03, 1.38278e+03, 8.38572e-01, 0.00000e+00],\n",
       "        [7.46007e+02, 1.63791e+02, 7.79548e+02, 2.19061e+02, 8.37310e-01, 0.00000e+00],\n",
       "        [1.14234e+03, 7.25872e+02, 1.18160e+03, 7.85555e+02, 8.33452e-01, 0.00000e+00],\n",
       "        [1.28350e+03, 1.69889e+03, 1.34053e+03, 1.78646e+03, 8.31392e-01, 0.00000e+00],\n",
       "        [1.20805e+03, 1.23356e+03, 1.26233e+03, 1.31258e+03, 8.31268e-01, 0.00000e+00],\n",
       "        [6.81445e+02, 5.70501e+02, 7.24268e+02, 6.32826e+02, 8.30987e-01, 0.00000e+00],\n",
       "        [1.21193e+03, 1.25789e+02, 1.25339e+03, 1.90748e+02, 8.28833e-01, 0.00000e+00],\n",
       "        [1.33997e+03, 1.54883e+03, 1.39766e+03, 1.63437e+03, 8.28785e-01, 0.00000e+00],\n",
       "        [1.54749e+03, 2.23149e+03, 1.60175e+03, 2.30905e+03, 8.25733e-01, 0.00000e+00],\n",
       "        [8.52919e+02, 2.11543e+03, 9.05219e+02, 2.19237e+03, 8.25538e-01, 0.00000e+00],\n",
       "        [1.12275e+03, 8.10812e+02, 1.15636e+03, 8.57932e+02, 7.92192e-01, 0.00000e+00],\n",
       "        [7.37790e+02, 2.20819e+03, 7.74526e+02, 2.26228e+03, 7.89918e-01, 0.00000e+00]])"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "suited-experience",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[1.45282e+03, 1.45009e+03, 1.50923e+03, 1.53559e+03, 8.58536e-01, 0.00000e+00],\n",
       "         [8.11149e+02, 2.51468e+02, 8.65843e+02, 3.34357e+02, 8.56946e-01, 0.00000e+00],\n",
       "         [1.32890e+03, 6.14181e+02, 1.38540e+03, 6.95824e+02, 8.49743e-01, 0.00000e+00],\n",
       "         [1.32848e+03, 1.39324e+03, 1.36927e+03, 1.45567e+03, 8.44309e-01, 0.00000e+00],\n",
       "         [8.95427e+02, 1.55035e+02, 9.40290e+02, 2.22714e+02, 8.43017e-01, 0.00000e+00],\n",
       "         [8.04034e+02, 4.29946e+02, 8.54911e+02, 5.09081e+02, 8.40511e-01, 0.00000e+00],\n",
       "         [1.42461e+03, 2.20768e+03, 1.47910e+03, 2.29305e+03, 8.38835e-01, 0.00000e+00],\n",
       "         [1.33620e+03, 1.30665e+03, 1.38581e+03, 1.38278e+03, 8.38572e-01, 0.00000e+00],\n",
       "         [7.46007e+02, 1.63791e+02, 7.79548e+02, 2.19061e+02, 8.37310e-01, 0.00000e+00],\n",
       "         [1.14234e+03, 7.25872e+02, 1.18160e+03, 7.85555e+02, 8.33452e-01, 0.00000e+00],\n",
       "         [1.28350e+03, 1.69889e+03, 1.34053e+03, 1.78646e+03, 8.31392e-01, 0.00000e+00],\n",
       "         [1.20805e+03, 1.23356e+03, 1.26233e+03, 1.31258e+03, 8.31268e-01, 0.00000e+00],\n",
       "         [6.81445e+02, 5.70501e+02, 7.24268e+02, 6.32826e+02, 8.30987e-01, 0.00000e+00],\n",
       "         [1.21193e+03, 1.25789e+02, 1.25339e+03, 1.90748e+02, 8.28833e-01, 0.00000e+00],\n",
       "         [1.33997e+03, 1.54883e+03, 1.39766e+03, 1.63437e+03, 8.28785e-01, 0.00000e+00],\n",
       "         [1.54749e+03, 2.23149e+03, 1.60175e+03, 2.30905e+03, 8.25733e-01, 0.00000e+00],\n",
       "         [8.52919e+02, 2.11543e+03, 9.05219e+02, 2.19237e+03, 8.25538e-01, 0.00000e+00],\n",
       "         [1.12275e+03, 8.10812e+02, 1.15636e+03, 8.57932e+02, 7.92192e-01, 0.00000e+00],\n",
       "         [7.37790e+02, 2.20819e+03, 7.74526e+02, 2.26228e+03, 7.89918e-01, 0.00000e+00],\n",
       "         [1.23392e+03, 1.27033e+03, 1.23707e+03, 1.27623e+03, 6.64147e-01, 0.00000e+00],\n",
       "         [8.27529e+02, 4.66882e+02, 8.30594e+02, 4.72392e+02, 6.63699e-01, 0.00000e+00],\n",
       "         [1.35932e+03, 1.34197e+03, 1.36236e+03, 1.34754e+03, 6.58507e-01, 0.00000e+00],\n",
       "         [8.77805e+02, 2.15140e+03, 8.80863e+02, 2.15687e+03, 6.54635e-01, 0.00000e+00],\n",
       "         [1.57291e+03, 2.26772e+03, 1.57595e+03, 2.27312e+03, 6.52650e-01, 0.00000e+00],\n",
       "         [1.35525e+03, 6.52543e+02, 1.35833e+03, 6.58060e+02, 6.41166e-01, 0.00000e+00],\n",
       "         [1.45012e+03, 2.24749e+03, 1.45353e+03, 2.25408e+03, 6.34566e-01, 0.00000e+00],\n",
       "         [8.37390e+02, 2.89459e+02, 8.40605e+02, 2.95434e+02, 6.31863e-01, 0.00000e+00],\n",
       "         [1.47993e+03, 1.48860e+03, 1.48322e+03, 1.49462e+03, 6.27043e-01, 0.00000e+00],\n",
       "         [1.31047e+03, 1.74061e+03, 1.31396e+03, 1.74714e+03, 6.23834e-01, 0.00000e+00],\n",
       "         [1.36719e+03, 1.58846e+03, 1.37050e+03, 1.59472e+03, 6.18528e-01, 0.00000e+00],\n",
       "         [1.23135e+03, 1.56254e+02, 1.23416e+03, 1.61483e+02, 6.11631e-01, 0.00000e+00],\n",
       "         [1.34732e+03, 1.42185e+03, 1.35014e+03, 1.42707e+03, 6.06137e-01, 0.00000e+00],\n",
       "         [7.00657e+02, 6.00105e+02, 7.03530e+02, 6.05261e+02, 6.00729e-01, 0.00000e+00],\n",
       "         [9.16384e+02, 1.85675e+02, 9.19341e+02, 1.91016e+02, 5.99634e-01, 0.00000e+00],\n",
       "         [1.16060e+03, 7.53294e+02, 1.16341e+03, 7.58378e+02, 5.64768e-01, 0.00000e+00]])]"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bottom-semester",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
