{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "derived-trial",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "scikit-learn version 0.24.1 is not supported. Minimum required version: 0.17. Maximum required version: 0.19.2. Disabling scikit-learn conversion API.\n",
      "TensorFlow version 2.5.0 detected. Last version known to be fully compatible is 2.3.1 .\n",
      "Keras version 2.5.0 detected. Last version known to be fully compatible of Keras is 2.2.4 .\n",
      "Adding op 'pow' of type pow\n",
      "Adding op 'pow_y_0' of type const\n",
      "Adding op 'mul_1' of type mul\n",
      "Adding op 'mul_1_x_0' of type const\n",
      "Adding op 'add' of type add\n",
      "Adding op 'mul_2' of type mul\n",
      "Adding op 'mul_2_x_0' of type const\n",
      "Adding op 'tanh' of type tanh\n",
      "Adding op 'add_1' of type add\n",
      "Adding op 'add_1_x_0' of type const\n",
      "Adding op 'mul' of type mul\n",
      "Adding op 'mul_x_0' of type const\n",
      "Adding op 'mul_3' of type mul\n",
      "Adding op 'pow' of type pow\n",
      "Adding op 'pow_y_1' of type const\n",
      "Adding op 'mul_1' of type mul\n",
      "Adding op 'mul_1_x_1' of type const\n",
      "Adding op 'add' of type add\n",
      "Adding op 'mul_2' of type mul\n",
      "Adding op 'mul_2_x_1' of type const\n",
      "Adding op 'tanh' of type tanh\n",
      "Adding op 'add_1' of type add\n",
      "Adding op 'add_1_x_1' of type const\n",
      "Adding op 'mul' of type mul\n",
      "Adding op 'mul_x_1' of type const\n",
      "Adding op 'mul_3' of type mul\n",
      "Adding op 'main_reduce' of type reduce_mean\n",
      "Adding op 'main_reduce_axes_0' of type const\n",
      "Adding op 'main_reduce_keep_dims_0' of type const\n",
      "Adding op 'sub' of type sub\n",
      "Adding op 'square' of type square\n",
      "Adding op 'reduce_mean_2' of type reduce_mean\n",
      "Adding op 'reduce_mean_2_axes_0' of type const\n",
      "Adding op 'reduce_mean_2_keep_dims_0' of type const\n",
      "Adding op 'add_epsilon' of type add\n",
      "Adding op 'add_epsilon_y_0' of type const\n",
      "Adding op 'rsqrt' of type rsqrt\n",
      "Adding op 'rsqrt_epsilon_0' of type const\n",
      "Adding op 'mul_gamma' of type mul\n",
      "Adding op 'mul_gamma_y_0' of type const\n",
      "Adding op 'mul_2' of type mul\n",
      "Adding op 'mul_3' of type mul\n",
      "Adding op 'sub_beta' of type sub\n",
      "Adding op 'sub_beta_x_0' of type const\n",
      "Adding op 'add_2' of type add\n",
      "Adding op 'main_reduce' of type reduce_mean\n",
      "Adding op 'main_reduce_axes_1' of type const\n",
      "Adding op 'main_reduce_keep_dims_1' of type const\n",
      "Adding op 'sub0' of type sub\n",
      "Adding op 'sub1' of type sub\n",
      "Adding op 'square' of type square\n",
      "Adding op 'mean1' of type reduce_mean\n",
      "Adding op 'mean1_axes_0' of type const\n",
      "Adding op 'mean1_keep_dims_0' of type const\n",
      "Adding op 'add_epsilon' of type add\n",
      "Adding op 'add_epsilon_y_1' of type const\n",
      "Adding op 'pow' of type pow\n",
      "Adding op 'pow_y_2' of type const\n",
      "Adding op 'real_div' of type real_div\n",
      "Adding op 'mul_gamma' of type mul\n",
      "Adding op 'mul_gamma_x_0' of type const\n",
      "Adding op 'add_beta' of type add\n",
      "Adding op 'add_beta_x_0' of type const\n",
      "Adding op 'main_reduce' of type reduce_mean\n",
      "Adding op 'main_reduce_axes_2' of type const\n",
      "Adding op 'main_reduce_keep_dims_2' of type const\n",
      "Adding op 'sub' of type sub\n",
      "Adding op 'square' of type square\n",
      "Adding op 'mean1' of type reduce_mean\n",
      "Adding op 'mean1_axes_1' of type const\n",
      "Adding op 'mean1_keep_dims_1' of type const\n",
      "Adding op 'add_epsilon' of type add\n",
      "Adding op 'add_epsilon_y_2' of type const\n",
      "Adding op 'rsqrt' of type rsqrt\n",
      "Adding op 'rsqrt_epsilon_1' of type const\n",
      "Adding op 'mul1' of type mul\n",
      "Adding op 'mul2' of type mul\n",
      "Adding op 'mul_sub' of type mul\n",
      "Adding op 'mul_sub_y_0' of type const\n",
      "Adding op 'add' of type add\n",
      "Adding op 'mul_square1' of type mul\n",
      "Adding op 'main_reduce' of type reduce_sum\n",
      "Adding op 'main_reduce_axes_3' of type const\n",
      "Adding op 'main_reduce_keep_dims_3' of type const\n",
      "Adding op 'mul_mean' of type mul\n",
      "Adding op 'mul_mean_y_0' of type const\n",
      "Adding op 'mul_square' of type mul\n",
      "Adding op 'sum1' of type reduce_sum\n",
      "Adding op 'sum1_axes_0' of type const\n",
      "Adding op 'sum1_keep_dims_0' of type const\n",
      "Adding op 'mul_mean1' of type mul\n",
      "Adding op 'mul_mean1_y_0' of type const\n",
      "Adding op 'sub_variance' of type sub\n",
      "Adding op 'add_epsilon' of type add\n",
      "Adding op 'add_epsilon_y_3' of type const\n",
      "Adding op 'rsqrt' of type rsqrt\n",
      "Adding op 'rsqrt_epsilon_2' of type const\n",
      "Adding op 'mul_gamma' of type mul\n",
      "Adding op 'mul_gamma_y_1' of type const\n",
      "Adding op 'mul1' of type mul\n",
      "Adding op 'mul2' of type mul\n",
      "Adding op 'sub_beta' of type sub\n",
      "Adding op 'sub_beta_x_1' of type const\n",
      "Adding op 'add' of type add\n",
      "Adding op 'linear' of type linear\n",
      "Adding op 'linear_weight_0' of type const\n",
      "Adding op 'linear_bias_0' of type const\n",
      "Adding op 'add_or_sub' of type add\n",
      "Adding op 'add_or_sub_y_0' of type const\n",
      "Adding op 'linear' of type linear\n",
      "Adding op 'linear_weight_1' of type const\n",
      "Adding op 'linear_bias_1' of type const\n",
      "Adding op 'add_or_sub' of type sub\n",
      "Adding op 'add_or_sub_y_1' of type const\n",
      "Adding op 'conv' of type conv\n",
      "Adding op 'conv_weight_0' of type const\n",
      "Adding op 'conv_pad_type_0' of type const\n",
      "Adding op 'conv_strides_0' of type const\n",
      "Adding op 'conv_pad_0' of type const\n",
      "Adding op 'conv_dilations_0' of type const\n",
      "Adding op 'conv_groups_0' of type const\n",
      "Adding op 'batchnorm' of type batch_norm\n",
      "Adding op 'batchnorm_mean_0' of type const\n",
      "Adding op 'batchnorm_variance_0' of type const\n",
      "Adding op 'batchnorm_epsilon_0' of type const\n",
      "Adding op 'conv' of type conv_transpose\n",
      "Adding op 'conv_weight_1' of type const\n",
      "Adding op 'conv_pad_type_1' of type const\n",
      "Adding op 'conv_pad_1' of type const\n",
      "Adding op 'conv_strides_1' of type const\n",
      "Adding op 'conv_dilations_1' of type const\n",
      "Adding op 'conv_groups_1' of type const\n",
      "Adding op 'batchnorm' of type batch_norm\n",
      "Adding op 'batchnorm_mean_1' of type const\n",
      "Adding op 'batchnorm_variance_1' of type const\n",
      "Adding op 'batchnorm_epsilon_1' of type const\n",
      "Adding op 'conv' of type conv\n",
      "Adding op 'conv_weight_2' of type const\n",
      "Adding op 'conv_pad_type_2' of type const\n",
      "Adding op 'conv_strides_2' of type const\n",
      "Adding op 'conv_pad_2' of type const\n",
      "Adding op 'conv_dilations_2' of type const\n",
      "Adding op 'conv_groups_2' of type const\n",
      "Adding op 'scale' of type mul\n",
      "Adding op 'scale_y_0' of type const\n",
      "Adding op 'conv' of type conv_transpose\n",
      "Adding op 'conv_weight_3' of type const\n",
      "Adding op 'conv_pad_type_3' of type const\n",
      "Adding op 'conv_pad_3' of type const\n",
      "Adding op 'conv_strides_3' of type const\n",
      "Adding op 'conv_dilations_3' of type const\n",
      "Adding op 'conv_groups_3' of type const\n",
      "Adding op 'scale' of type mul\n",
      "Adding op 'scale_y_1' of type const\n",
      "Adding op 'conv' of type conv\n",
      "Adding op 'conv_weight_4' of type const\n",
      "Adding op 'conv_pad_type_4' of type const\n",
      "Adding op 'conv_strides_4' of type const\n",
      "Adding op 'conv_pad_4' of type const\n",
      "Adding op 'conv_dilations_4' of type const\n",
      "Adding op 'conv_groups_4' of type const\n",
      "Adding op 'scale' of type real_div\n",
      "Adding op 'scale_y_2' of type const\n",
      "Adding op 'cast_0' of type cast\n",
      "Adding op 'cast_0_dtype_0' of type const\n",
      "Adding op 'conv' of type conv_transpose\n",
      "Adding op 'conv_weight_5' of type const\n",
      "Adding op 'conv_pad_type_5' of type const\n",
      "Adding op 'conv_pad_5' of type const\n",
      "Adding op 'conv_strides_5' of type const\n",
      "Adding op 'conv_dilations_5' of type const\n",
      "Adding op 'conv_groups_5' of type const\n",
      "Adding op 'scale' of type real_div\n",
      "Adding op 'scale_y_3' of type const\n",
      "Adding op 'cast_1' of type cast\n",
      "Adding op 'cast_1_dtype_0' of type const\n"
     ]
    }
   ],
   "source": [
    "from utils.general import scale_coords, non_max_suppression, xyxy2xywh, xywhn2xyxy, xyxy2xywhn\n",
    "import coremltools\n",
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import PIL.Image\n",
    "import PIL.ImageDraw \n",
    "import shutil\n",
    "import time\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "equivalent-choir",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters and Global variables\n",
    "MODE = 'debug'\n",
    "SAVE_IMG = True\n",
    "VIEW_IMG = False\n",
    "SAVE_TXT = True\n",
    "ENSEMBLE = False\n",
    "CAT_NAMES = ['Screw', 'unknown']\n",
    "\n",
    "# Anchor box can be checked in pytorch model\n",
    "ANCHORS = ([2.375,3.375, 5.5,5, 4.75,11.75], \n",
    "           [6,4.25, 5.375,9.5, 11.25,8.5625], \n",
    "           [4.375,9.40625, 9.46875,8.25, 7.43750,16.93750],\n",
    "           [6.81250,9.60938, 11.54688,5.93750, 14.45312,12.37500])\n",
    "# stide can be check in pytorch model\n",
    "stride = [8, 16, 32, 64]\n",
    "# target size of input image (width, height)\n",
    "IMG_SIZE = (2304, 3072)\n",
    "# confidence threshold\n",
    "conf_thres = .2\n",
    "\n",
    "\n",
    "# Params and global variables that should be kept as it is\n",
    "COLORS = [[random.randint(0, 255) for _ in range(3)] for _ in range(len(CAT_NAMES))]\n",
    "PATH = \"./\"\n",
    "nc = len(CAT_NAMES)\n",
    "nl = len(ANCHORS)\n",
    "na = len(ANCHORS[0]) // 2\n",
    "no = nc + 5\n",
    "# initiate grid and anchor_grid\n",
    "grid = [torch.zeros(1)] * nl\n",
    "a = torch.tensor(ANCHORS).float().view(nl, -1, 2)\n",
    "anchor_grid = [torch.zeros(1)] * nl\n",
    "\n",
    "\n",
    "COREML_MODEL = [\"/Users/zhenyu/Box/MLProject:IphoneAOI/weights/yolov5l6_3072*2304_20211116/weights/best.mlmodel\",\n",
    "                \"/Users/zhenyu/Box/MLProject:IphoneAOI/weights/yolov5l6_3072*2304_20211124/weights/best.mlmodel\"]\n",
    "IMAGE_FOLDER = \"/Users/zhenyu/Desktop/val/\"\n",
    "OUT_FOLDER = \"/Users/zhenyu/Desktop/test/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "printable-tours",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_grid(nx=20, ny=20, i=0):\n",
    "    yv, xv = torch.meshgrid([torch.arange(ny), torch.arange(nx)])\n",
    "    grid = torch.stack((xv, yv), 2).view((1, 1, ny, nx, 2)).float()\n",
    "    anchor_grid = (a[i] * stride[i]).view((1, na, 1, 1, 2)).expand(1, na, ny, nx, 2).float()\n",
    "    return grid, anchor_grid\n",
    "\n",
    "def resize_image(source_image):\n",
    "    background = PIL.Image.new('RGB', IMG_SIZE, \"black\")\n",
    "    source_image.thumbnail(IMG_SIZE)\n",
    "    (w, h) = source_image.size\n",
    "    background.paste(source_image, (int((IMG_SIZE[0] - w) / 2), int((IMG_SIZE[1] - h) / 2 )))\n",
    "    return background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "applicable-signature",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(image, model, file_name):\n",
    "    resized = resize_image(image.copy())\n",
    "\n",
    "    predictions = model.predict({'image': resized})\n",
    "\n",
    "    z = []  # inference output\n",
    "    x = []\n",
    "    for head in ['var_1763', 'var_1778', 'var_1793', 'var_1808']:\n",
    "        x.append(torch.Tensor(predictions[head]))\n",
    "\n",
    "    for i in range(nl):\n",
    "        bs, _, ny, nx, _ = x[i].shape\n",
    "\n",
    "        # if grid[i].shape[2:4] != x[i].shape[2:4]:\n",
    "        grid[i], anchor_grid = make_grid(nx, ny, i)\n",
    "\n",
    "        y = x[i].sigmoid()\n",
    "        y[..., 0:2] = (y[..., 0:2] * 2. - 0.5 + grid[i]) * stride[i]  # xy\n",
    "        y[..., 2:4] = (y[..., 2:4] * 2) ** 2 * anchor_grid  # wh\n",
    "        z.append(y.view(bs, -1, no))\n",
    "    \n",
    "    pred = torch.cat(z, 1)\n",
    "    \n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "hawaiian-beach",
   "metadata": {},
   "outputs": [],
   "source": [
    "def debug(model_list):\n",
    "    if os.path.exists(OUT_FOLDER):\n",
    "        shutil.rmtree(OUT_FOLDER)\n",
    "    os.makedirs(OUT_FOLDER)\n",
    "    \n",
    "    time_tracker = {}\n",
    "    time_sum = 0\n",
    "    for img_path in tqdm(os.listdir(IMAGE_FOLDER)):\n",
    "        if img_path.endswith(\".jpg\") and not img_path.startswith('.'):\n",
    "            image = PIL.Image.open(os.path.join(IMAGE_FOLDER, img_path))\n",
    "            draw = PIL.ImageDraw.Draw(image)\n",
    "            pred = torch.tensor([])\n",
    "            t0 = time.time()\n",
    "            for model in model_list:\n",
    "                pred = torch.cat((pred, eval(image, model, img_path)), 1)\n",
    "            nms = non_max_suppression(pred, conf_thres, .3, classes=None, agnostic=False)[0]\n",
    "            label=[]\n",
    "            for *xyxy, _, cls in nms:\n",
    "                if SAVE_TXT:\n",
    "                    xywh = xyxy2xywhn(torch.tensor(xyxy).view(1, 4), w=IMG_SIZE[0], h=IMG_SIZE[1]).view(-1).tolist()\n",
    "                    label.append(('%g ' * 5 + '\\n') % (cls, *xywh))\n",
    "                if SAVE_IMG:\n",
    "                    draw.rectangle(np.array(torch.tensor(xyxy).view(2,2)*1.3125), outline='red', width=6)\n",
    "            if SAVE_TXT:\n",
    "                with open(os.path.join(OUT_FOLDER, '{}.txt'.format(img_path[:-4])), 'a') as f:\n",
    "                    for line in label:\n",
    "                        f.write(line)\n",
    "            if SAVE_IMG:\n",
    "                image.save(os.path.join(OUT_FOLDER, '{}.jpg'.format(img_path[:-4])))\n",
    "            delta_t = time.time() - t0\n",
    "            time_tracker[img_path] = delta_t\n",
    "        break\n",
    "    for key, item in time_tracker.items():\n",
    "        print('{} takes {} seconds'.format(key, item))\n",
    "        time_sum += item\n",
    "    print('Averange process time is {}'.format(time_sum/len(time_tracker)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "protective-dealing",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_list = [coremltools.models.model.MLModel(model) for model in COREML_MODEL]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "electrical-family",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/70 [00:03<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16EWQV5RIM.jpg takes 3.5988080501556396 seconds\n",
      "Averange process time is 3.5988080501556396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "debug(model_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "scientific-shaft",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([19, 6])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "det.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "robust-offset",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 440640, 7])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat(z, 1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "twenty-offer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 440640])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((torch.cat(z, 1))[:,:,4] > 0.5).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "collective-serial",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered = torch.cat(z, 1)[torch.where(torch.cat(z, 1)[:,:,4]>0.2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "approximate-baking",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([238])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered[:,-1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "extra-dylan",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-4b1bb5f097e5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: __init__() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "torch.nn.Sigmoid(filtered[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "residential-essence",
   "metadata": {},
   "outputs": [],
   "source": [
    "det = torch.cat((det, det))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "hired-today",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = torch.cat((torch.cat(z, 1), torch.cat(z, 1)), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "acting-fundamental",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 881280, 7])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "hindu-meditation",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_det = non_max_suppression(test, 0.2, .3, classes=None, agnostic=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "secondary-provincial",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([19, 6])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_det[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "stylish-preliminary",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.46316e+03, 1.47392e+03, 1.49889e+03, 1.51176e+03, 8.58536e-01, 0.00000e+00],\n",
       "        [8.21176e+02, 2.74568e+02, 8.55816e+02, 3.11257e+02, 8.56946e-01, 0.00000e+00],\n",
       "        [1.33926e+03, 6.36934e+02, 1.37504e+03, 6.73071e+02, 8.49743e-01, 0.00000e+00],\n",
       "        [1.33596e+03, 1.41064e+03, 1.36180e+03, 1.43827e+03, 8.44309e-01, 0.00000e+00],\n",
       "        [9.03651e+02, 1.73896e+02, 9.32065e+02, 2.03853e+02, 8.43017e-01, 0.00000e+00],\n",
       "        [8.13361e+02, 4.52000e+02, 8.45583e+02, 4.87027e+02, 8.40511e-01, 0.00000e+00],\n",
       "        [1.43460e+03, 2.23147e+03, 1.46911e+03, 2.26926e+03, 8.38835e-01, 0.00000e+00],\n",
       "        [1.34529e+03, 1.32787e+03, 1.37672e+03, 1.36156e+03, 8.38572e-01, 0.00000e+00],\n",
       "        [7.52156e+02, 1.79194e+02, 7.73399e+02, 2.03658e+02, 8.37310e-01, 0.00000e+00],\n",
       "        [1.14954e+03, 7.42505e+02, 1.17441e+03, 7.68922e+02, 8.33452e-01, 0.00000e+00],\n",
       "        [1.29396e+03, 1.72329e+03, 1.33008e+03, 1.76205e+03, 8.31392e-01, 0.00000e+00],\n",
       "        [1.21800e+03, 1.25558e+03, 1.25238e+03, 1.29056e+03, 8.31268e-01, 0.00000e+00],\n",
       "        [6.89296e+02, 5.87870e+02, 7.16417e+02, 6.15457e+02, 8.30987e-01, 0.00000e+00],\n",
       "        [1.21953e+03, 1.43892e+02, 1.24579e+03, 1.72644e+02, 8.28833e-01, 0.00000e+00],\n",
       "        [1.35055e+03, 1.57267e+03, 1.38709e+03, 1.61053e+03, 8.28785e-01, 0.00000e+00],\n",
       "        [1.55744e+03, 2.25311e+03, 1.59180e+03, 2.28743e+03, 8.25733e-01, 0.00000e+00],\n",
       "        [8.62508e+02, 2.13687e+03, 8.95630e+02, 2.17092e+03, 8.25538e-01, 0.00000e+00],\n",
       "        [1.12891e+03, 8.23944e+02, 1.15020e+03, 8.44800e+02, 7.92192e-01, 0.00000e+00],\n",
       "        [7.44525e+02, 2.22327e+03, 7.67791e+02, 2.24721e+03, 7.89918e-01, 0.00000e+00],\n",
       "        [1.46316e+03, 1.47392e+03, 1.49889e+03, 1.51176e+03, 8.58536e-01, 0.00000e+00],\n",
       "        [8.21176e+02, 2.74568e+02, 8.55816e+02, 3.11257e+02, 8.56946e-01, 0.00000e+00],\n",
       "        [1.33926e+03, 6.36934e+02, 1.37504e+03, 6.73071e+02, 8.49743e-01, 0.00000e+00],\n",
       "        [1.33596e+03, 1.41064e+03, 1.36180e+03, 1.43827e+03, 8.44309e-01, 0.00000e+00],\n",
       "        [9.03651e+02, 1.73896e+02, 9.32065e+02, 2.03853e+02, 8.43017e-01, 0.00000e+00],\n",
       "        [8.13361e+02, 4.52000e+02, 8.45583e+02, 4.87027e+02, 8.40511e-01, 0.00000e+00],\n",
       "        [1.43460e+03, 2.23147e+03, 1.46911e+03, 2.26926e+03, 8.38835e-01, 0.00000e+00],\n",
       "        [1.34529e+03, 1.32787e+03, 1.37672e+03, 1.36156e+03, 8.38572e-01, 0.00000e+00],\n",
       "        [7.52156e+02, 1.79194e+02, 7.73399e+02, 2.03658e+02, 8.37310e-01, 0.00000e+00],\n",
       "        [1.14954e+03, 7.42505e+02, 1.17441e+03, 7.68922e+02, 8.33452e-01, 0.00000e+00],\n",
       "        [1.29396e+03, 1.72329e+03, 1.33008e+03, 1.76205e+03, 8.31392e-01, 0.00000e+00],\n",
       "        [1.21800e+03, 1.25558e+03, 1.25238e+03, 1.29056e+03, 8.31268e-01, 0.00000e+00],\n",
       "        [6.89296e+02, 5.87870e+02, 7.16417e+02, 6.15457e+02, 8.30987e-01, 0.00000e+00],\n",
       "        [1.21953e+03, 1.43892e+02, 1.24579e+03, 1.72644e+02, 8.28833e-01, 0.00000e+00],\n",
       "        [1.35055e+03, 1.57267e+03, 1.38709e+03, 1.61053e+03, 8.28785e-01, 0.00000e+00],\n",
       "        [1.55744e+03, 2.25311e+03, 1.59180e+03, 2.28743e+03, 8.25733e-01, 0.00000e+00],\n",
       "        [8.62508e+02, 2.13687e+03, 8.95630e+02, 2.17092e+03, 8.25538e-01, 0.00000e+00],\n",
       "        [1.12891e+03, 8.23944e+02, 1.15020e+03, 8.44800e+02, 7.92192e-01, 0.00000e+00],\n",
       "        [7.44525e+02, 2.22327e+03, 7.67791e+02, 2.24721e+03, 7.89918e-01, 0.00000e+00]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "det"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "painful-classification",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "angry-utility",
   "metadata": {},
   "outputs": [],
   "source": [
    "nms = torchvision.ops.batched_nms(filtered[:, :4], filtered[:,4], torch.zeros(238), 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "choice-struggle",
   "metadata": {},
   "outputs": [],
   "source": [
    "nms_2 = torchvision.ops.nms(filtered[:, :4], filtered[:,4], 0.002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "bottom-fighter",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([238])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nms_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "republican-reliance",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([238])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nms.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "another-elevation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1920.39917, 1934.51636, 1967.29089, 1984.18787],\n",
       "        [1077.79346,  360.37067, 1123.25842,  408.52469],\n",
       "        [1757.78149,  835.97528, 1804.74536,  883.40521],\n",
       "        [1753.44934, 1851.46826, 1787.35620, 1887.73499],\n",
       "        [1186.04248,  228.23886, 1223.33496,  267.55649],\n",
       "        [1067.53662,  593.25043, 1109.82812,  639.22321],\n",
       "        [1882.91309, 2928.81055, 1928.20496, 2978.40283],\n",
       "        [1765.69824, 1742.82629, 1806.93884, 1787.05200],\n",
       "        [ 987.20459,  235.19218, 1015.08563,  267.30124],\n",
       "        [1508.77087,  974.53760, 1541.40808, 1009.21039],\n",
       "        [1698.31812, 2261.82373, 1745.72803, 2312.69653],\n",
       "        [1598.62537, 1647.95447, 1643.74414, 1693.85962],\n",
       "        [ 904.70117,  771.58002,  940.29749,  807.78735],\n",
       "        [1600.63879,  188.85822, 1635.09924,  226.59567],\n",
       "        [1772.59631, 2064.13086, 1820.55225, 2113.82202],\n",
       "        [2044.13940, 2957.20068, 2089.24390, 3002.25830],\n",
       "        [1132.04114, 2804.63940, 1175.51489, 2849.33813],\n",
       "        [1481.69922, 1081.42603, 1509.63635, 1108.79980],\n",
       "        [ 977.18884, 2918.04028, 1007.72577, 2949.46338]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "det[:,:4]*1.3125"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "minus-breach",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_anchor():\n",
    "    from models.experimental import attempt_load  # scoped to avoid circular import\n",
    "    w = '/Users/zhenyu/Library/CloudStorage/Box-Box/MLProject:IphoneAOI/weights/yolov5l6_3072*2304_20211203/weights/best.pt'\n",
    "    model_pt = torch.jit.load(w) if 'torchscript' in w else attempt_load(w)\n",
    "    print('Anchors are:\\n {}'.format(model_pt.model[-1].anchors))\n",
    "    print(model_pt.model[-1].grid[0].shape)\n",
    "    print(model_pt.model[-1].grid[1].shape)\n",
    "    print(model_pt.model[-1].grid[2].shape)\n",
    "    print(model_pt.model[-1].grid[3].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "overhead-council",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fusing layers... \n",
      "Model Summary: 476 layers, 76126356 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anchors are:\n",
      " tensor([[[ 2.37500,  3.37500],\n",
      "         [ 5.50000,  5.00000],\n",
      "         [ 4.75000, 11.75000]],\n",
      "\n",
      "        [[ 6.00000,  4.25000],\n",
      "         [ 5.37500,  9.50000],\n",
      "         [11.25000,  8.56250]],\n",
      "\n",
      "        [[ 4.37500,  9.40625],\n",
      "         [ 9.46875,  8.25000],\n",
      "         [ 7.43750, 16.93750]],\n",
      "\n",
      "        [[ 6.81250,  9.60938],\n",
      "         [11.54688,  5.93750],\n",
      "         [14.45312, 12.37500]]])\n",
      "torch.Size([1, 3, 392, 296, 2])\n",
      "torch.Size([1, 3, 196, 148, 2])\n",
      "torch.Size([1, 3, 98, 74, 2])\n",
      "torch.Size([1, 3, 49, 37, 2])\n"
     ]
    }
   ],
   "source": [
    "get_anchor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "weird-average",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fusing layers... \n",
      "Model Summary: 476 layers, 76126356 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anchors are:\n",
      " tensor([[[ 2.37500,  3.37500],\n",
      "         [ 5.50000,  5.00000],\n",
      "         [ 4.75000, 11.75000]],\n",
      "\n",
      "        [[ 6.00000,  4.25000],\n",
      "         [ 5.37500,  9.50000],\n",
      "         [11.25000,  8.56250]],\n",
      "\n",
      "        [[ 4.37500,  9.40625],\n",
      "         [ 9.46875,  8.25000],\n",
      "         [ 7.43750, 16.93750]],\n",
      "\n",
      "        [[ 6.81250,  9.60938],\n",
      "         [11.54688,  5.93750],\n",
      "         [14.45312, 12.37500]]])\n",
      "torch.Size([1, 3, 392, 296, 2])\n",
      "torch.Size([1, 3, 196, 148, 2])\n",
      "torch.Size([1, 3, 98, 74, 2])\n",
      "torch.Size([1, 3, 49, 37, 2])\n"
     ]
    }
   ],
   "source": [
    "get_anchor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "derived-oracle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.1415926535897936"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float('3.141592653589793423634534795')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alternate-repeat",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
