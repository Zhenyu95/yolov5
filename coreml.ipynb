{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fifty-finland",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:TensorFlow version 2.5.0 detected. Last version known to be fully compatible is 2.3.1 .\n",
      "WARNING:root:Keras version 2.5.0 detected. Last version known to be fully compatible of Keras is 2.2.4 .\n"
     ]
    }
   ],
   "source": [
    "from models.yolo import Detect\n",
    "from utils.general import scale_coords, non_max_suppression, xyxy2xywh, save_one_box\n",
    "import coremltools\n",
    "from PIL import Image\n",
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "import cv2\n",
    "import os\n",
    "import shutil\n",
    "import PIL.Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "purple-letters",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONSTANTS\n",
    "COREML_MODEL = \"/Users/zhenyu/Documents/Scripts/IphoneAOI/yolov5/best.mlmodel\"\n",
    "IMAGE_FOLDER = \"/Users/zhenyu/Desktop/val/\"\n",
    "OUT_FOLDER = \"/Users/zhenyu/Desktop/test/\"\n",
    "SAVE_IMG = True\n",
    "VIEW_IMG = False\n",
    "SAVE_TXT = False\n",
    "CAT_NAMES = ['Screw', 'unknown']\n",
    "COLORS = [[random.randint(0, 255) for _ in range(3)] for _ in range(len(CAT_NAMES))]\n",
    "PATH = \"./\"\n",
    "ANCHORS = ([116,90, 156,198, 373,326], [30,61, 62,45, 59,119], [10,13, 16,30, 33,23]) # from <model>.yml\n",
    "IMG_SIZE = (2560, 2560)\n",
    "\n",
    "# GLOBAL VARIABLES\n",
    "nc = len(CAT_NAMES)\n",
    "nl = len(ANCHORS)\n",
    "na = len(ANCHORS[0]) // 2\n",
    "no = nc + 5  # number of outputs per anchor\n",
    "grid = [torch.zeros(1)] * nl  # init grid\n",
    "a = torch.tensor(ANCHORS).float().view(nl, -1, 2)\n",
    "anchor_grid = a.clone().view(nl, 1, -1, 1, 1, 2)\n",
    "stride = [32, 16, 8] # check your model config\n",
    "conf_thres = .3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "different-guide",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(path, resize_to=None):\n",
    "    # resize_to: (Width, Height)\n",
    "    img = PIL.Image.open(path)\n",
    "    if resize_to is not None:\n",
    "        img = img.resize(resize_to, PIL.Image.ANTIALIAS)\n",
    "    img_np = np.array(img).astype(np.float32)\n",
    "    return img_np, img\n",
    "\n",
    "def make_grid(nx=20, ny=20):\n",
    "    yv, xv = torch.meshgrid([torch.arange(ny), torch.arange(nx)])\n",
    "    return torch.stack((xv, yv), 2).view((1, 1, ny, nx, 2)).float()\n",
    "\n",
    "def resize_image(source_image):\n",
    "    background = Image.new('RGB', IMG_SIZE, \"black\")\n",
    "    source_image.thumbnail(IMG_SIZE)\n",
    "    (w, h) = source_image.size\n",
    "    background.paste(source_image, (int((IMG_SIZE[0] - w) / 2), int((IMG_SIZE[1] - h) / 2 )))\n",
    "    return background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "commercial-compiler",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_np, img_load = load_image(IMAGE_FOLDER+ '0CSRBMHQM6.jpg', resize_to=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "heavy-index",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = PIL.Image.open(os.path.join(IMAGE_FOLDER, '0CSRBMHQM6.jpg'))\n",
    "image0shape = np.array(image).astype(np.float32).shape\n",
    "resized = resize_image(image)\n",
    "img = np.array(resized).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "developmental-update",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4032, 3008, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image0shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "superior-latin",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4032, 3008, 3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "lesbian-nature",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = PIL.Image.open(os.path.join(IMAGE_FOLDER, '0CSRBMHQM6.jpg')).crop((0,0, 2560, 2560))\n",
    "img.save('/Users/zhenyu/Desktop/test/1.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "curious-adventure",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = [torch.tensor(np.array([[1, 2, 3], [4, 5, 6]]))]\n",
    "x = torch.ones((1,3))\n",
    "# z[0].shape\n",
    "(torch.cat(z, 1), x)[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "metallic-supervision",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(file_name):   \n",
    "    # image = resize_image(image)\n",
    "    # _, image = load_image(IMAGE_FOLDER+file_name, resize_to=IMG_SIZE)\n",
    "    \n",
    "    image = Image.open(os.path.join(IMAGE_FOLDER, file_name))\n",
    "    image = resize_image(image)\n",
    "    \n",
    "    img = torch.zeros((1,3,IMG_SIZE[0],IMG_SIZE[1]))\n",
    "    img[0, :, :, :] = torch.Tensor(np.array(image)).permute(2, 0, 1)\n",
    "    im0 = np.array(img)\n",
    "\n",
    "    predictions = model.predict({'image': img})\n",
    "\n",
    "    z = []  # inference output\n",
    "    x = []\n",
    "    for pred in predictions:\n",
    "        x.append(torch.Tensor(predictions[pred]))\n",
    "    x.reverse()\n",
    "\n",
    "    for i in range(nl):\n",
    "        bs, _, ny, nx, _ = x[i].shape\n",
    "\n",
    "        if grid[i].shape[2:4] != x[i].shape[2:4]:\n",
    "            grid[i] = make_grid(nx, ny)\n",
    "\n",
    "        y = x[i].sigmoid()\n",
    "        y[..., 0:2] = (y[..., 0:2] * 2. - 0.5 + grid[i]) * stride[i]  # xy\n",
    "        y[..., 2:4] = (y[..., 2:4] * 2) ** 2 * anchor_grid[i]  # wh\n",
    "        z.append(y.view(bs, -1, no))\n",
    "\n",
    "    pred = (torch.cat(z, 1), x)[0]\n",
    "\n",
    "    pred = non_max_suppression(pred, conf_thres, .5, classes=None, agnostic=False)\n",
    "\n",
    "    # Process detections\n",
    "    for i, det in enumerate(pred):  # detections per image\n",
    "        p, s = \"./\", \"\"\n",
    "\n",
    "        if det is not None and len(det):\n",
    "            # Rescale boxes from img_size to im0 size\n",
    "            # TODO potential bug HERE!!!!!!!!!!!!!!!!\n",
    "            det[:, :4] = scale_coords(img.shape[2:], det[:, :4], im0.shape).round()\n",
    "\n",
    "            # Print results\n",
    "            for c in det[:, -1].unique():\n",
    "                n = (det[:, -1] == c).sum()  # detections per class\n",
    "                s += '%g %ss, ' % (n, CAT_NAMES[int(c)])  # add to string\n",
    "\n",
    "            # Write results\n",
    "            for *xyxy, conf, cls in det:\n",
    "                if SAVE_TXT:  # Write to file\n",
    "                    xywh = (xyxy2xywh(torch.tensor(xyxy).view(1, 4)) / gn).view(-1).tolist()  # normalized xywh\n",
    "                    with open(os.path.join(OUT_FOLDER, 'predictions.txt'), 'a') as f:\n",
    "                        f.write(('%g ' * 5 + '\\n') % (cls, *xywh))  # label format\n",
    "\n",
    "                if SAVE_IMG or VIEW_IMG:  # Add bbox to image\n",
    "                    label = '%s %.2f' % (CAT_NAMES[int(cls)], conf)\n",
    "                    save_one_box(xyxy, im0, file='label.jpg', BGR=True)\n",
    "\n",
    "    if SAVE_IMG:\n",
    "        cv2.imwrite(os.path.join(OUT_FOLDER, file_name), im0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "different-junior",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    global model\n",
    "    if os.path.exists(OUT_FOLDER):\n",
    "        shutil.rmtree(OUT_FOLDER)\n",
    "    os.makedirs(OUT_FOLDER)\n",
    "\n",
    "    # Load the model\n",
    "    model = coremltools.models.model.MLModel(COREML_MODEL)\n",
    "\n",
    "    image_files = os.listdir(IMAGE_FOLDER)\n",
    "\n",
    "    for i_f in image_files:\n",
    "        eval(i_f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
